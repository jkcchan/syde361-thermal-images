{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall Detection from Thermal Images\n",
    "SYDE 361\n",
    "\n",
    "Prof. J. Kofman\n",
    "\n",
    "Staff Advisor: Prof. Alex Wong\n",
    "\n",
    "Group 6 - Semin Bae, Jacob Chan, Janno Joulu, Chenlei Shen, Hassan Almusawi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.stats import rayleigh\n",
    "import scipy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from labelled data, distribution of area\n",
    "mu = 517.51266145227532\n",
    "std = 781.92552992055425\n",
    "size= 5000\n",
    "pdf_fitted = rayleigh.pdf(scipy.arange(size), mu, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CCA_from_image(image, threshold = 115, show_image=False):\n",
    "    img = cv2.imread(image,0)\n",
    "    h,w = img.shape[:2]\n",
    "    if show_image:\n",
    "        fig,ax = plt.subplots(1)\n",
    "\n",
    "\n",
    "    ret, thresh = cv2.threshold(img,threshold,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    output = cv2.connectedComponentsWithStats(thresh, 8, cv2.CV_32S)\n",
    "    num_labels = output[0]\n",
    "    labels = output[1]\n",
    "    stats = output[2]\n",
    "    centroids = output[3]\n",
    "\n",
    "    max_area_index=-1\n",
    "    for i in range(len(stats)):\n",
    "        if stats[i][0]==0 and stats[i][1]==0:\n",
    "            continue\n",
    "        if show_image:\n",
    "            ax.add_patch(\n",
    "                patches.Rectangle(\n",
    "                    (stats[i][0], stats[i][1]),\n",
    "                    stats[i][2],\n",
    "                    stats[i][3],\n",
    "                    fill=False,      # remove background\n",
    "                    color='red'\n",
    "                )\n",
    "            )\n",
    "        if max_area_index==-1:\n",
    "            max_area_index=i\n",
    "        elif stats[i][4] > stats[max_area_index][4]:\n",
    "            max_area_index=i\n",
    "            \n",
    "    if show_image:\n",
    "        ax.imshow(thresh, cmap='gray')\n",
    "        plt.show()\n",
    "    chosen_box = thresh[stats[max_area_index][1]:stats[max_area_index][1]+stats[max_area_index][3],stats[max_area_index][0]:stats[max_area_index][0]+stats[max_area_index][2]]\n",
    "    return stats[max_area_index], chosen_box, thresh, img\n",
    "\n",
    "\n",
    "def get_best_threshold(img_filename, pdf, start=30, max_steps =100, alpha=1, show_graph = False):\n",
    "    index = -1\n",
    "    final_chosen_box = None\n",
    "    final_stats = []\n",
    "    final_img = None\n",
    "    final_thresh = None\n",
    "    thresholds = np.arange(start,start+max_steps,alpha)\n",
    "    min_score = -1\n",
    "    if show_graph:\n",
    "        areas = []\n",
    "        ratios = []\n",
    "        scores=[]\n",
    "    for i in thresholds:\n",
    "        stats, chosen_box, thresh, img = get_CCA_from_image(img_filename, i, show_image=False)\n",
    "        ratio = get_ratio_of_image(chosen_box)\n",
    "        score= (1-ratio)*pdf[chosen_box.size]\n",
    "        if show_graph:\n",
    "            scores.append(score)\n",
    "            areas.append(chosen_box.size)\n",
    "            ratios.append(ratio)\n",
    "        if score > min_score:\n",
    "            min_score = score\n",
    "            index = i\n",
    "            final_chosen_box = chosen_box\n",
    "            final_stats = stats\n",
    "            final_thresh = thresh\n",
    "            final_img = img\n",
    "    if show_graph:\n",
    "        plt.title('ratios')\n",
    "        plt.xlabel('threshold value')\n",
    "        plt.ylabel('ratio of white pixels to black pixels')\n",
    "        plt.plot(ratios)\n",
    "        plt.show()\n",
    "        plt.title('areas')\n",
    "        plt.xlabel('threshold value')\n",
    "        plt.ylabel('area of bounding box')\n",
    "        plt.plot(areas)\n",
    "        plt.show()\n",
    "        plt.title('scores')\n",
    "        plt.xlabel('threshold value')\n",
    "        plt.ylabel('score')\n",
    "        plt.plot(scores)\n",
    "        return index, final_chosen_box, final_stats, final_thresh, final_img, areas,ratios\n",
    "    return index, final_chosen_box, final_stats, final_thresh, final_img, score\n",
    "\n",
    "def get_ratio_of_image(img):\n",
    "    a=cv2.countNonZero(img)\n",
    "    h,w = img.shape[:2]\n",
    "    return float(float(a)/(float(h)*float(w)))\n",
    "\n",
    "def get_rotated_box(image_filename, output = False, max_area = 2700):\n",
    "    images = []\n",
    "    threshold, chosen_box, stats, thresh, img = get_best_threshold(image_filename, start=40)\n",
    "    im2,contours,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "    areas = []\n",
    "    for cont in contours:\n",
    "        areas.append(cv2.contourArea(cont))\n",
    "    areas = np.array(areas)\n",
    "    cont = contours[np.argmax(areas[areas < max_area])]\n",
    "    rect = cv2.minAreaRect(cont)\n",
    "    if output:\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        images.append(thresh)\n",
    "        a = cv2.drawContours(thresh,[box],0,(255, 255,0),2)\n",
    "        plt.imshow(thresh, cmap=\"gray\")\n",
    "        plt.show()\n",
    "    return rect[1][0]*rect[1][1], max(rect[1][0]/rect[1][1],rect[1][1]/rect[1][0])\n",
    "\n",
    "def get_features(filename, pdf, output=False):\n",
    "    index, final_chosen_box, final_stats, final_thresh, final_img, score = get_best_threshold(filename, pdf)\n",
    "    features = []\n",
    "    area = final_stats[2]*final_stats[3]\n",
    "    features.append(area)\n",
    "    bb_ratio =max((float(final_stats[2])/float(final_stats[3])),(float(final_stats[3])/float(final_stats[2])))\n",
    "    features.append(bb_ratio)\n",
    "    hu_moments = cv2.HuMoments(cv2.moments(final_chosen_box))\n",
    "    features.extend(hu_moments.T[0].tolist())\n",
    "    variance = np.var(final_chosen_box)\n",
    "    features.append(variance) \n",
    "    if output:\n",
    "        fig,ax = plt.subplots(1)\n",
    "        ax.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (final_stats[0], final_stats[1]),\n",
    "                final_stats[2],\n",
    "                final_stats[3],\n",
    "                fill=False,      # remove background\n",
    "                color='red'\n",
    "            )\n",
    "        )\n",
    "        print \"threshold used: \" + str(index)\n",
    "        ax.imshow(final_thresh, cmap='gray')\n",
    "        plt.show()\n",
    "        print \"area: \"+str(area)\n",
    "        print \"bb_ratio: \"+ str(bb_ratio)\n",
    "        print \"hu_moments: \"+np.array2string(hu_moments.T[0])\n",
    "        print \"variance: \"+str(variance)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(features, scl):\n",
    "    if not scl:\n",
    "        return\n",
    "    if len(features) != (scl.min_).shape[0]:\n",
    "        return\n",
    "    return scl.transform([features])\n",
    "\n",
    "def classify_with_scaled_features(scaled_features, clf, probabilities = False):\n",
    "    if not clf:\n",
    "        return\n",
    "    if probabilities:\n",
    "        return clf.predict(scaled_features), clf.predict_proba(scaled_features)\n",
    "    return clf.predict(scaled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models used:\n",
    "- Logistic Regression\n",
    "- SVM (Linear Kernel)\n",
    "- SVM (RBF)\n",
    "- Gaussian Process Classifier\n",
    "- Quadratic Discriminant Analysis\n",
    "- k-Nearest Neighbors\n",
    "\n",
    "Data used:\n",
    "- \"regression_3.csv\"\n",
    "- \"regression_3_test.csv\"\n",
    "\n",
    "Split:\n",
    "- 25%\n",
    "\n",
    "Scaling used:\n",
    "- `sklearn.preprocessing.MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn import gaussian_process\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn import neighbors\n",
    "\n",
    "def classify(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction = clf.predict(X_test)\n",
    "    return clf, accuracy_score(y_test, prediction), mean_squared_error(y_test, prediction),r2_score(y_test, prediction), precision_score(y_test, prediction), recall_score(y_test, prediction)\n",
    "\n",
    "def train(dataset=\"dataset.csv\",scale=True, features=['falling','area','bb_ratio','hu1','hu2','hu3','hu4','hu5','hu6','hu7','variance'], test_size=0.25 ):\n",
    "    classifiers = [(\"Logistic Regression\",linear_model.LogisticRegression()),\n",
    "                   (\"Linear SVM\",svm.SVC()), \n",
    "                   (\"Non-Linear SVM\",svm.SVC(gamma=2, C=1, probability=True)), \n",
    "                   (\"GPC\", gaussian_process.GaussianProcessClassifier()), \n",
    "                   (\"QDA\",discriminant_analysis.QuadraticDiscriminantAnalysis()),\n",
    "                   (\"kNN\",neighbors.KNeighborsClassifier())]\n",
    "    performance = {}\n",
    "\n",
    "# {'clf':[], 'accuracy_score':[], 'mse' :[], 'r2':[]}\n",
    "    data = pd.read_csv(dataset)\n",
    "    data = data.reset_index()[features]\n",
    "    y = data.falling\n",
    "    X = data.drop(['falling'], axis=1)\n",
    "    if scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        X = X_scaled\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    for i in classifiers:\n",
    "        performance[i[0]] = []\n",
    "        for j in range(0,100):\n",
    "            x = [i[0]]\n",
    "            x.extend(classify(i[1],X_train, X_test, y_train, y_test))\n",
    "            performance[i[0]].append(x)\n",
    "    to_return = []\n",
    "    for i in performance:\n",
    "        for j in np.array(performance[i]).reshape((-1,7)):\n",
    "            to_return.append(j)\n",
    "    clf_df = pd.DataFrame(data=to_return, columns=['type','clf','acc','mse','r2','prec','rec'])\n",
    "    if scale:\n",
    "        return clf_df, scaler\n",
    "    return clf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(directory, output=False, output_full_image=False):\n",
    "    import os\n",
    "    pdf_fitted = rayleigh.pdf(scipy.arange(5000), 517.51266145227532, 781.92552992055425)\n",
    "    feature_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if '.jpg' in file:\n",
    "                feature_vector = []\n",
    "                filepath = os.path.join(root, file)\n",
    "                if 'lying' in filepath:\n",
    "                    feature_vector.append(1)\n",
    "                else:\n",
    "                    feature_vector.append(0)\n",
    "                features = get_features(filepath, pdf_fitted, output)\n",
    "                feature_vector.extend(features)\n",
    "                feature_list.append(feature_vector)\n",
    "    return pd.DataFrame(data=feature_list,columns = ['falling','area','bb_ratio','hu1','hu2','hu3','hu4','hu5','hu6','hu7','variance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(output=False):\n",
    "    df = build_dataset(\"./dataset/\", output)\n",
    "    df.to_csv('dataset.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "Model selection: best average `accuracy_score`\n",
    "\n",
    "Classifier selection: best `accuracy_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(performance, best = False):\n",
    "    if best:\n",
    "        best_class = None\n",
    "        best_score = -1\n",
    "        for i in performance:\n",
    "            if performance[i]['avg_score'] > best_score:\n",
    "                best_score = performance[i]['avg_score']\n",
    "                best_class = i\n",
    "        classifier = performance[best_class]\\\n",
    "        ['clf'][np.argmax(performance[best_class]['accuracy_score'])]\n",
    "        return classifier\n",
    "    else:\n",
    "        classifiers = []\n",
    "        for i in performance:\n",
    "            classifiers.append(performance[i]['clf'][np.argmax(performance[i]['accuracy_score'])])\n",
    "        return classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(classifier, scaler, clf_name = 'classifier.pkl',scl_name = 'scaler.pkl'):\n",
    "    from sklearn.externals import joblib\n",
    "    joblib.dump(classifier, clf_name) \n",
    "    joblib.dump(scaler, scl_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf, scl = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>clf</th>\n",
       "      <th>acc</th>\n",
       "      <th>mse</th>\n",
       "      <th>r2</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type                                                clf       acc       mse  \\\n",
       "0  kNN  KNeighborsClassifier(algorithm='auto', leaf_si...  0.952381  0.047619   \n",
       "1  kNN  KNeighborsClassifier(algorithm='auto', leaf_si...  0.952381  0.047619   \n",
       "2  kNN  KNeighborsClassifier(algorithm='auto', leaf_si...  0.952381  0.047619   \n",
       "3  kNN  KNeighborsClassifier(algorithm='auto', leaf_si...  0.952381  0.047619   \n",
       "4  kNN  KNeighborsClassifier(algorithm='auto', leaf_si...  0.952381  0.047619   \n",
       "\n",
       "         r2      prec  rec  \n",
       "0  0.809524  0.913043  1.0  \n",
       "1  0.809524  0.913043  1.0  \n",
       "2  0.809524  0.913043  1.0  \n",
       "3  0.809524  0.913043  1.0  \n",
       "4  0.809524  0.913043  1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPC</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.115816e-16</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>3.347448e-16</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.115816e-16</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Linear SVM</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.115816e-16</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>2.231632e-16</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.115816e-16</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count      mean           std       min       25%  \\\n",
       "type                                                                     \n",
       "GPC                  100.0  0.904762  1.115816e-16  0.904762  0.904762   \n",
       "Linear SVM           100.0  0.785714  3.347448e-16  0.785714  0.785714   \n",
       "Logistic Regression  100.0  0.904762  1.115816e-16  0.904762  0.904762   \n",
       "Non-Linear SVM       100.0  0.904762  1.115816e-16  0.904762  0.904762   \n",
       "QDA                  100.0  0.880952  2.231632e-16  0.880952  0.880952   \n",
       "kNN                  100.0  0.952381  1.115816e-16  0.952381  0.952381   \n",
       "\n",
       "                          50%       75%       max  \n",
       "type                                               \n",
       "GPC                  0.904762  0.904762  0.904762  \n",
       "Linear SVM           0.785714  0.785714  0.785714  \n",
       "Logistic Regression  0.904762  0.904762  0.904762  \n",
       "Non-Linear SVM       0.904762  0.904762  0.904762  \n",
       "QDA                  0.880952  0.880952  0.880952  \n",
       "kNN                  0.952381  0.952381  0.952381  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.groupby('type').describe()['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "### Model Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_model(clf_name = 'classifier.pkl',scl_name = 'scaler.pkl'):\n",
    "    from sklearn.externals import joblib\n",
    "    clf = joblib.load(clf_name)\n",
    "    scl = joblib.load(scl_name)\n",
    "    return clf, scl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2664, 1.945945945945946, 0.0009743570416946188, 3.5363295421404633e-07, 7.249538940610172e-12, 4.5316198213948075e-12, 1.64582980141422e-23, 1.0531653275105492e-16, -2.009384013936279e-23, 8091.2552755458182]\n",
      "[[ 0.87328312  0.3993994   0.11714451  0.08869879  0.00310256  0.00379461\n",
      "   0.05543299  0.18067753  0.59127328  0.28837408]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1]), array([[ 0.06226283,  0.93773717]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf, scl = import_model()\n",
    "features = get_features('latest.jpg', pdf_fitted)\n",
    "print features\n",
    "scaled_features = scale_features(features, scl)\n",
    "print scaled_features\n",
    "classify_with_scaled_features(scaled_features, clf, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
