{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall Detection from Thermal Images\n",
    "SYDE 361\n",
    "Prof. J. Kofman\n",
    "Advisor: Prof. Alex Wong\n",
    "Group 6 - Semin Bae, Jacob Chan, Janno Joulu, Chenlei Shen, Hassan Almusawi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.stats import rayleigh\n",
    "import scipy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from labelled data, distribution of area\n",
    "mu = 517.51266145227532\n",
    "std = 781.92552992055425\n",
    "size= 5000\n",
    "pdf_fitted = rayleigh.pdf(scipy.arange(size), mu, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CCA_from_image(image, threshold = 115, show_image=False):\n",
    "    img = cv2.imread(image,0)\n",
    "    h,w = img.shape[:2]\n",
    "    if show_image:\n",
    "        fig,ax = plt.subplots(1)\n",
    "\n",
    "    L = measure.label(img)\n",
    "\n",
    "    ret, thresh = cv2.threshold(img,threshold,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    output = cv2.connectedComponentsWithStats(thresh, 8, cv2.CV_32S)\n",
    "    num_labels = output[0]\n",
    "    labels = output[1]\n",
    "    stats = output[2]\n",
    "    centroids = output[3]\n",
    "\n",
    "    max_area_index=-1\n",
    "    for i in range(len(stats)):\n",
    "        if stats[i][0]==0 and stats[i][1]==0:\n",
    "            continue\n",
    "        if show_image:\n",
    "            ax.add_patch(\n",
    "                patches.Rectangle(\n",
    "                    (stats[i][0], stats[i][1]),\n",
    "                    stats[i][2],\n",
    "                    stats[i][3],\n",
    "                    fill=False,      # remove background\n",
    "                    color='red'\n",
    "                )\n",
    "            )\n",
    "        if max_area_index==-1:\n",
    "            max_area_index=i\n",
    "        elif stats[i][4] > stats[max_area_index][4]:\n",
    "            max_area_index=i\n",
    "            \n",
    "    if show_image:\n",
    "        ax.imshow(thresh, cmap='gray')\n",
    "        plt.show()\n",
    "    chosen_box = thresh[stats[max_area_index][1]:stats[max_area_index][1]+stats[max_area_index][3],stats[max_area_index][0]:stats[max_area_index][0]+stats[max_area_index][2]]\n",
    "    return stats[max_area_index], chosen_box, thresh, img\n",
    "\n",
    "\n",
    "def get_best_threshold(img_filename, pdf, start=30, max_steps =100, alpha=1, show_graph = False):\n",
    "    index = -1\n",
    "    final_chosen_box = None\n",
    "    final_stats = []\n",
    "    final_img = None\n",
    "    final_thresh = None\n",
    "    thresholds = np.arange(start,start+max_steps,alpha)\n",
    "    min_score = -1\n",
    "    if show_graph:\n",
    "        areas = []\n",
    "        ratios = []\n",
    "        scores=[]\n",
    "    for i in thresholds:\n",
    "        stats, chosen_box, thresh, img = get_CCA_from_image(img_filename, i, show_image=False)\n",
    "        ratio = get_ratio_of_image(chosen_box)\n",
    "        score= (1-ratio)*pdf[chosen_box.size]\n",
    "        if show_graph:\n",
    "            scores.append(score)\n",
    "            areas.append(chosen_box.size)\n",
    "            ratios.append(ratio)\n",
    "        if score > min_score:\n",
    "            min_score = score\n",
    "            index = i\n",
    "            final_chosen_box = chosen_box\n",
    "            final_stats = stats\n",
    "            final_thresh = thresh\n",
    "            final_img = img\n",
    "    if show_graph:\n",
    "        plt.title('ratios')\n",
    "        plt.xlabel('threshold value')\n",
    "        plt.ylabel('ratio of white pixels to black pixels')\n",
    "        plt.plot(ratios)\n",
    "        plt.show()\n",
    "        plt.title('areas')\n",
    "        plt.xlabel('threshold value')\n",
    "        plt.ylabel('area of bounding box')\n",
    "        plt.plot(areas)\n",
    "        plt.show()\n",
    "        plt.title('scores')\n",
    "        plt.xlabel('threshold value')\n",
    "        plt.ylabel('score')\n",
    "        plt.plot(scores)\n",
    "        return index, final_chosen_box, final_stats, final_thresh, final_img, areas,ratios\n",
    "    return index, final_chosen_box, final_stats, final_thresh, final_img, score\n",
    "\n",
    "def get_ratio_of_image(img):\n",
    "    a=cv2.countNonZero(img)\n",
    "    h,w = img.shape[:2]\n",
    "    return float(float(a)/(float(h)*float(w)))\n",
    "\n",
    "def get_rotated_box(image_filename, output = False, max_area = 2700):\n",
    "    images = []\n",
    "    threshold, chosen_box, stats, thresh, img = get_best_threshold(image_filename, start=40)\n",
    "    im2,contours,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "    areas = []\n",
    "    for cont in contours:\n",
    "        areas.append(cv2.contourArea(cont))\n",
    "    areas = np.array(areas)\n",
    "    cont = contours[np.argmax(areas[areas < max_area])]\n",
    "    rect = cv2.minAreaRect(cont)\n",
    "    if output:\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        images.append(thresh)\n",
    "        a = cv2.drawContours(thresh,[box],0,(255, 255,0),2)\n",
    "        plt.imshow(thresh, cmap=\"gray\")\n",
    "        plt.show()\n",
    "    return rect[1][0]*rect[1][1], max(rect[1][0]/rect[1][1],rect[1][1]/rect[1][0])\n",
    "\n",
    "def get_features(filename, pdf, output=False):\n",
    "    index, final_chosen_box, final_stats, final_thresh, final_img, score = get_best_threshold(filename, pdf)\n",
    "    features = []\n",
    "    area = final_stats[2]*final_stats[3]\n",
    "    features.append(area)\n",
    "    bb_ratio =max((float(final_stats[2])/float(final_stats[3])),(float(final_stats[3])/float(final_stats[2])))\n",
    "    features.append(bb_ratio)\n",
    "    hu_moments = cv2.HuMoments(cv2.moments(final_chosen_box))\n",
    "    features.extend(hu_moments.T[0].tolist())\n",
    "    variance = np.var(final_chosen_box)\n",
    "    features.append(variance) \n",
    "    if output:\n",
    "        print \"threshold used: \" + str(index)\n",
    "        plt.imshow(final_chosen_box, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        print \"area: \"+str(area)\n",
    "        print \"bb_ratio: \"+ str(bb_ratio)\n",
    "        print \"hu_moments: \"+np.array2string(hu_moments.T[0])\n",
    "        print \"variance: \"+str(variance)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(features, scl):\n",
    "    if not scl:\n",
    "        return\n",
    "    if len(features) != (scl.min_).shape[0]:\n",
    "        return\n",
    "    return scl.transform([features])\n",
    "\n",
    "def classify_with_scaled_features(scaled_features, clf, probabilities = False):\n",
    "    if not clf:\n",
    "        return\n",
    "    if probabilities:\n",
    "        return clf.predict(scaled_features), clf.predict_proba(scaled_features)\n",
    "    return clf.predict(scaled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models used:\n",
    "- Logistic Regression\n",
    "- SVM (Linear Kernel)\n",
    "- SVM (RBF)\n",
    "- Gaussian Process Classifier\n",
    "- Quadratic Discriminant Analysis\n",
    "- k-Nearest Neighbors\n",
    "\n",
    "Data used:\n",
    "- \"regression_3.csv\"\n",
    "- \"regression_3_test.csv\"\n",
    "\n",
    "Split:\n",
    "- 25%\n",
    "\n",
    "Scaling used:\n",
    "- `sklearn.preprocessing.MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    import pandas as pd\n",
    "    from sklearn import datasets, linear_model\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn import svm\n",
    "    from sklearn import gaussian_process\n",
    "    from sklearn import discriminant_analysis\n",
    "    from sklearn import neighbors\n",
    "\n",
    "    classifiers = [linear_model.LogisticRegression(),\n",
    "                   svm.SVC(), \n",
    "                   svm.SVC(gamma=2, C=1), \n",
    "                   gaussian_process.GaussianProcessClassifier(), \n",
    "                   discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "                   neighbors.KNeighborsClassifier()]\n",
    "    performance = {}\n",
    "\n",
    "    def classify(clf, X_train, X_test, y_train, y_test):\n",
    "        clf.fit(X_train, y_train)\n",
    "        prediction = clf.predict(X_test)\n",
    "        return clf, accuracy_score(y_test, prediction), mean_squared_error(y_test, prediction),r2_score(y_test, prediction)\n",
    "\n",
    "    for i in classifiers:\n",
    "        performance[str(type(i))] = {'clf':[], 'accuracy_score':[], 'mse' :[], 'r2':[]}\n",
    "    data = pd.read_csv('dataset.csv')\n",
    "    data = data.reset_index()[['falling','area','bb_ratio','hu1','hu2','hu3','hu4','hu5','hu6','hu7','variance']]\n",
    "    y = data.falling\n",
    "    X = data.drop(['falling'], axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    for j in range(0,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "        for i in classifiers:\n",
    "            clf, accuracy_score_value, mse_value, r2_value = classify(i,X_train, X_test, y_train, y_test)\n",
    "            performance[str(type(i))]['clf'].append(clf)\n",
    "            performance[str(type(i))]['accuracy_score'].append(accuracy_score_value)\n",
    "            performance[str(type(i))]['mse'].append(mse_value)\n",
    "            performance[str(type(i))]['r2'].append(r2_value)\n",
    "    for i in classifiers:\n",
    "        performance[str(type(i))]['avg_score'] = np.average(performance[str(type(i))]['accuracy_score'])\n",
    "        performance[str(type(i))]['avg_mse'] = np.average(performance[str(type(i))]['mse'])\n",
    "        performance[str(type(i))]['avg_r2'] = np.average(performance[str(type(i))]['r2'])\n",
    "    return performance, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(directory, output=False):\n",
    "    import os\n",
    "    pdf_fitted = rayleigh.pdf(scipy.arange(5000), 517.51266145227532, 781.92552992055425)\n",
    "    feature_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if '.jpg' in file:\n",
    "                feature_vector = []\n",
    "                filepath = os.path.join(root, file)\n",
    "                if 'lying' in filepath:\n",
    "                    feature_vector.append(1)\n",
    "                else:\n",
    "                    feature_vector.append(0)\n",
    "                features = get_features(filepath, pdf_fitted, output)\n",
    "                feature_vector.extend(features)\n",
    "                feature_list.append(feature_vector)\n",
    "    return pd.DataFrame(data=feature_list,columns = ['falling','area','bb_ratio','hu1','hu2','hu3','hu4','hu5','hu6','hu7','variance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(output=False):\n",
    "    df = build_dataset(\"./dataset/\", output)\n",
    "    df.to_csv('dataset.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "Model selection: best average `accuracy_score`\n",
    "\n",
    "Classifier selection: best `accuracy_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(performance, best = False):\n",
    "    if best:\n",
    "        best_class = None\n",
    "        best_score = -1\n",
    "        for i in performance:\n",
    "            if performance[i]['avg_score'] > best_score:\n",
    "                best_score = performance[i]['avg_score']\n",
    "                best_class = i\n",
    "        classifier = performance[best_class]\\\n",
    "        ['clf'][np.argmax(performance[best_class]['accuracy_score'])]\n",
    "        return classifier\n",
    "    else:\n",
    "        classifiers = []\n",
    "        for i in performance:\n",
    "            classifiers.append(performance[i]['clf'][np.argmax(performance[i]['accuracy_score'])])\n",
    "        return classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(classifier, scaler, clf_name = 'classifier.pkl',scl_name = 'scaler.pkl'):\n",
    "    from sklearn.externals import joblib\n",
    "    joblib.dump(classifier, clf_name) \n",
    "    joblib.dump(scaler, scl_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf, scl = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = select_model(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model(model[-2], scl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "### Model Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_model():\n",
    "    from sklearn.externals import joblib\n",
    "    clf = joblib.load('classifier.pkl')\n",
    "    scl = joblib.load('scaler.pkl')\n",
    "    return clf, scl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, scl = import_model()\n",
    "features = get_features('full-dataset/dataset1(rgb22).jpg', pdf_fitted)\n",
    "print features\n",
    "scaled_features = scale_features(features, scl)\n",
    "print scaled_features\n",
    "classify_with_scaled_features(scaled_features, clf, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
